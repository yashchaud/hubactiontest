# Lightweight Configuration for GTX 1050 (2GB VRAM)
# Copy this to .env for local testing on low-end GPU

# Service settings
SERVICE_PORT=8000
SERVICE_HOST=0.0.0.0
WORKERS=1

# Model settings - OPTIMIZED FOR LOW VRAM
TEXT_DETECTION_CONFIDENCE=0.75
NSFW_DETECTION_CONFIDENCE=0.90
AUDIO_PROFANITY_CONFIDENCE=0.85

# Performance settings - CRITICAL FOR LOW VRAM
FRAME_SAMPLE_RATE=5           # Process only every 5th frame (6 FPS detection)
MAX_CONCURRENT_STREAMS=1      # Only 1 stream at a time
GPU_MEMORY_FRACTION=0.95      # Use maximum available VRAM

# Feature toggles - DISABLE HEAVY MODELS
ENABLE_TEXT_DETECTION=true    # KEEP - Uses ~800MB
ENABLE_NSFW_DETECTION=false   # DISABLE - Saves ~400MB
ENABLE_AUDIO_PROFANITY=false  # DISABLE - Use CPU version if needed
ENABLE_OBJECT_TRACKING=true   # KEEP - Only ~50MB

# Blur settings - REDUCED FOR PERFORMANCE
BLUR_KERNEL_SIZE=31           # Smaller = faster (was 51)
BLUR_SIGMA=15                 # Lower = faster (was 25)
BLUR_PADDING=5                # Less padding (was 10)

# Tracking settings - FASTEST TRACKER
TRACKER_TYPE=MOSSE            # Fastest tracker (was CSRT)
TRACKER_MAX_AGE=20            # Shorter tracking (was 30)
PREDICTION_FRAMES=2           # Less prediction (was 3)

# OpenAI API (for cloud Whisper instead of local)
OPENAI_API_KEY=                # Optional: Use cloud Whisper for audio

# Redis cache (optional)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Logging
LOG_LEVEL=INFO
LOG_DETECTIONS=false          # Disable to reduce overhead
LOG_PATH=/app/logs

# GPU Memory Management
# Force TensorFlow to use only 1.8GB
TF_FORCE_GPU_ALLOW_GROWTH=true
TF_GPU_MEMORY_LIMIT=1800

# Use smaller Whisper model (if enabled)
WHISPER_MODEL_SIZE=tiny       # Only 40MB (base=140MB, large=3GB)
ENABLE_LOCAL_WHISPER=false    # Use cloud API instead
